---
title: MongoDB Sink Connector
---

The MongoDB Sink Connector allows you to continuously store the data that appears in your
Kafka Topics in a MongoDB database. In this guide, we will walk you through
creating a DB Sink Connector with a MongoDB database for Upstash Kafka.

## Get Started

### Create a Kafka Cluster

<Info>
  If you do not have a Kafka cluster and/or topic already, follow [these
  steps](../overall/getstarted) to create one.
</Info>

### Create the Connector

Go to the Connectors tab, and create your first connector by clicking the **New
Connector** button.

<Frame>
  <img src="/img/kafka/connect/connector.png" width="100%" />
</Frame>

Choose the **MongoDB Connector Sink**

<Frame>
  <img src="/img/kafka/connect/mongo/sink/1connector.png" />
</Frame>

Enter a connector name and MongoDB URI (connection string). Select single or
multiple topics from existing topics to read data from.

Enter the Database and Collection where the selected topics will be written. We
entered "new" as Database and "test" as Collection. It is not required for this
database and collection to exist in the MongoDB database. They will be created
automatically.

<Frame>
  <img src="/img/kafka/connect/mongo/sink/2config.png" />
</Frame>

The advanced screen allows for any other configuration that the selected connector
supports. At the top of this screen, you can find a link to related
documentation. We can proceed with what we have and click the **Connect** button
directly.

<Frame>
  <img src="/img/kafka/connect/mongo/sink/3advanced.png" />
</Frame>

Congratulations! You have successfully created your MongoDB Sink Connector. As you put data
into your selected topics, the data will be written into your MongoDB database.
